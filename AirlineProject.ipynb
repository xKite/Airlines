{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d20ba05a",
   "metadata": {},
   "source": [
    "The purpose of this project is to conduct comprehensive analysis and gain actionable insights into customer feedback and airline performance. By combining SQL queries and Python data analysis techniques, this project aims to provide valuable information for airlines to improve service quality, enhance customer satisfaction, and make data-driven business decisions.\n",
    "\n",
    "Key Objectives:\n",
    "1. Data Exploration: Explore the provided database schema to understand the structure and relationships between tables.\n",
    "2. Data Preparation: Extract and preprocess relevant data for analysis.\n",
    "3. SQL Analysis: Utilize SQL queries to conduct exploratory analysis, such as calculating average ratings, analyzing traveler types and class of travel, and identifying top airlines by review count.\n",
    "4. Python Data Analysis: Apply Python data analysis libraries to visualize trends over time, perform sentiment analysis on reviews, and identify common themes in customer feedback.\n",
    "5. Performance Evaluation: Evaluate airline performance based on various metrics, including average ratings, distribution of traveler types, and sentiment analysis results.\n",
    "6. Insights and Recommendations: Generate actionable insights and recommendations for airlines based on the analysis findings, highlighting areas of strength and opportunities for improvement.\n",
    "7. Presentation and Reporting: Present the analysis results in a clear and visually appealing manner through charts, graphs, and dashboards. Prepare a comprehensive report summarizing key findings and recommendations for stakeholders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c51b0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from numpy import argmax\n",
    "from plotnine import *\n",
    "from pandas import DataFrame, read_csv\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import sqlalchemy as db\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.models import Sequential\n",
    "from keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from keras.layers import Dense\n",
    "\n",
    "#Please update the path of your dataset\n",
    "def readData():\n",
    "    colnames = ['Airline', 'Ratings', 'Snap Reviews', 'Country', 'Name', 'Date Travelled', 'Full Review', 'Aircraft Type', 'Traveller Type', 'Class of Travel', 'Travel Plans', 'Date Reviewed', 'Review Count']\n",
    "    SIA =  EVA = pd.read_excel('sia_excel.xlsx', names = colnames)\n",
    "    EVA = pd.read_excel('eva_data.xlsx', names = colnames)\n",
    "    ANA = pd.read_excel('ana_excel.xlsx', names = colnames)\n",
    "    Emirates = pd.read_excel('emirates_data.xlsx', names = colnames)\n",
    "    Lufthansa = pd.read_excel('luthansa_data.xlsx', names = colnames)\n",
    "    df = pd.concat([SIA, EVA, ANA, Emirates, Lufthansa])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5bcac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_ordinal(date_str):\n",
    "    if isinstance(date_str, str):  \n",
    "        return re.sub(r'\\b(\\d+)(st|nd|rd|th)\\b', r'\\1', date_str)\n",
    "    else:\n",
    "        return date_str  \n",
    "\n",
    "df = readData()  \n",
    "\n",
    "# Apply the function to the 'Date Travelled' column\n",
    "df['Date Travelled'] = df['Date Travelled'].apply(remove_ordinal)\n",
    "\n",
    "# Replace non-date values with NaN\n",
    "df['Date Travelled'] = pd.to_datetime(df['Date Travelled'], errors='coerce')\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0231de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove double quotes from the 'snap reviews' column\n",
    "df['Snap Reviews'] = df['Snap Reviews'].str.replace('\"', ' ')\n",
    "\n",
    "# Display the updated DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5cca54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove double quotes from the 'snap reviews' column\n",
    "df['Aircraft Type'] = df['Aircraft Type'].str.replace('Boeing ', 'B')\n",
    "\n",
    "# Display the updated DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f96ee3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63eeca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b71a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove non-numeric values from the 'Ratings' column\n",
    "df['Ratings'] = pd.to_numeric(df['Ratings'], errors='coerce')\n",
    "\n",
    "# Drop rows with NaN values in the 'Ratings' column\n",
    "df = df.dropna(subset=['Ratings'])\n",
    "\n",
    "# Calculate the mean of 'Ratings' grouped by 'Traveller Type'\n",
    "Seat = df.groupby('Traveller Type')['Ratings'].mean().reset_index().sort_values(by='Ratings', ascending=False)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 8))\n",
    "sns.barplot(x=\"Traveller Type\", y=\"Ratings\", data=Seat, ax=ax)\n",
    "\n",
    "for p in ax.patches:\n",
    "    ax.annotate(\"%0.2f\" % (p.get_height()), (p.get_x(), p.get_height() * 1.005))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6106359",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = df.groupby(['Airline','Aircraft Type'])['Ratings'].mean().reset_index()#.sort_values(by = 'OverallScore', ascending = False)\n",
    "dff1 = df.groupby(['Airline','Aircraft Type'])['Ratings'].count().reset_index()\n",
    "xx = pd.merge(dff,dff1, on = ['Airline','Aircraft Type'])\n",
    "xx = xx[xx['Ratings_y'] >=25].sort_values(by = 'Ratings_x', ascending = False)\n",
    "xx['Aircraft Type'] = xx['Airline'] + [' '] +xx['Aircraft Type']\n",
    "xx = xx.head(15)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,8))\n",
    "sns.barplot(x=\"Aircraft Type\", y=\"Ratings_x\", data=xx, ax=ax)\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation = 90)\n",
    "for p in ax.patches:\n",
    "    ax.annotate(\"%0.2f\"%(p.get_height()), (p.get_x(), p.get_height() * 1.005)) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73176647",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = df[df['Ratings'] != 0].groupby([\"Airline\", \"Ratings\"]).size().reset_index(name='Date Reviewed Count')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 12))\n",
    "sns.barplot(x=\"Airline\", y=\"Date Reviewed Count\", hue=\"Ratings\", data=t, ax=ax)\n",
    "\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation = 45)\n",
    "# for p in ax.patches:\n",
    "#     ax.annotate(\"%0.2f\"%(p.get_height()), (p.get_x() * 1.005, p.get_height() * 1.005))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e0795c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopSIA = ['Singapore', 'Airlines', 'SIA']\n",
    "df_SIA = df[df['Airline'] == 'SIA'].copy()  \n",
    "df_SIA.loc[:, 'Full Review'] = df_SIA['Full Review'].apply(lambda x: \" \".join(word for word in x.split() if word not in stopSIA))\n",
    "\n",
    "# Concatenate the text from all rows into a single string\n",
    "text = ' '.join(df_SIA['Full Review'])\n",
    "\n",
    "# Generate word cloud\n",
    "wc = WordCloud(background_color=\"white\", max_words=300, width=1000, height=600)\n",
    "wc.generate(text)\n",
    "\n",
    "# Display the word cloud\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.imshow(wc, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3738083",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[1600]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7b3c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Please update the path of your dataset\n",
    "folder_path = r'C:\\Users\\keiot\\OneDrive\\Documents\\01- Python\\To concate'\n",
    "\n",
    "# Get list of all files in the folder\n",
    "file_names = os.listdir(folder_path)\n",
    "\n",
    "# List comprehension to read each file into a DataFrame\n",
    "dataframes = [pd.read_excel(os.path.join(folder_path, file)) for file in file_names]\n",
    "\n",
    "# Concatenate the DataFrames\n",
    "concatenated_df = pd.concat(dataframes)\n",
    "\n",
    "# Reset index if needed\n",
    "concatenated_df.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb60894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the shape of the concatenated DataFrame\n",
    "print(\"Shape of concatenated DataFrame:\", concatenated_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5ab768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the data types of the columns in the concatenated DataFrame\n",
    "print(\"Data types of columns in the concatenated DataFrame:\")\n",
    "print(concatenated_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c024089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date_travelled and date_reviewed to datetime format\n",
    "concatenated_df['date_travelled'] = pd.to_datetime(concatenated_df['date_travelled'], errors='coerce')\n",
    "concatenated_df['date_reviewed'] = pd.to_datetime(concatenated_df['date_reviewed'], errors='coerce')\n",
    "\n",
    "# Now check the data types again\n",
    "print(concatenated_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36b396c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the concatenated DataFrame to 'airlineproject'\n",
    "airlineproject = concatenated_df.copy()\n",
    "\n",
    "# Now you have the concatenated DataFrame with the name 'airlineproject'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1357e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column 'review_id' and assign unique IDs to each review\n",
    "airlineproject['review_id'] = range(1, len(airlineproject) + 1)\n",
    "\n",
    "# Display the updated DataFrame to verify the changes\n",
    "airlineproject.head(10)\n",
    "print(airlineproject.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e069d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the 'Unnamed: 13' column from the DataFrame\n",
    "#airlineproject.drop(columns=['Unnamed: 13'], inplace=True)\n",
    "\n",
    "# Verify that the column has been dropped\n",
    "print(airlineproject.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b9bb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to an Excel file\n",
    "airlineproject.to_excel(\"airlineproject.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18df01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Table in PostgreSQL\n",
    "# Create connection engine\n",
    "\n",
    "#user postgres, password admin63, database airline01\n",
    "engine = db.create_engine('postgresql://postgres:admin63@localhost:5432/airline88') \n",
    "conn = engine.raw_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cfb582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new tables in PostgreSQL\n",
    "commands = (# TABLE : \n",
    "            ''' CREATE TABLE IF NOT EXISTS airlineproject (\n",
    "    airline VARCHAR(255),\n",
    "    ratings FLOAT,\n",
    "    snap_reviews TEXT,\n",
    "    country VARCHAR(255),\n",
    "    name VARCHAR(255),\n",
    "    date_travelled DATE,\n",
    "    full_review TEXT,\n",
    "    aircraft_type VARCHAR(255),\n",
    "    traveller_type VARCHAR(255),\n",
    "    class_travel VARCHAR(255),\n",
    "    travel_plans TEXT,\n",
    "    date_reviewed DATE,\n",
    "    review_count INTEGER,\n",
    "    review_id SERIAL PRIMARY KEY\n",
    ");''')\n",
    "            \n",
    "# Initialize connection to PostgreSQL\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Create cursor to execute SQL commands\n",
    "#for command in commands:\n",
    "cur.execute(commands)\n",
    "\n",
    "# Commit changes\n",
    "conn.commit()\n",
    "\n",
    "# Close communication with server\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d821447c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from the Excel file into a DataFrame\n",
    "airlineproject = pd.read_excel('airlineproject.xlsx')\n",
    "\n",
    "# Now the DataFrame airlineproject is defined and contains the data from the Excel file\n",
    "%who"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee7aa6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "airlineproject.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ce46ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the to_sql() method to import data into the PostgreSQL database\n",
    "airlineproject.to_sql(name='airlineproject', con=engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8be34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql('SELECT * FROM airlineproject', conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac36eee6",
   "metadata": {},
   "source": [
    "Data Analysis on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c1b135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plot of ratings by airline\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=df, x='airline', y='ratings')\n",
    "plt.title('Comparative Analysis of Airlines by Ratings')\n",
    "plt.xlabel('Airline')\n",
    "plt.ylabel('Ratings')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deeacac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date_reviewed to datetime\n",
    "df['date_reviewed'] = pd.to_datetime(df['date_reviewed'])\n",
    "\n",
    "# Line plot of ratings over time\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(data=df, x='date_reviewed', y='ratings', estimator='mean')\n",
    "plt.title('Temporal Analysis of Ratings')\n",
    "plt.xlabel('Date Reviewed')\n",
    "plt.ylabel('Average Rating')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d233288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by airline and traveller type, and calculate proportions\n",
    "traveller_type_proportions = df.groupby(['airline', 'traveller_type']).size() / df.groupby('airline').size()\n",
    "\n",
    "# Reshape data for plotting\n",
    "traveller_type_proportions = traveller_type_proportions.unstack(fill_value=0)\n",
    "\n",
    "# Plot stacked bar plot of traveller type preferences by airline\n",
    "plt.figure(figsize=(10, 6))\n",
    "traveller_type_proportions.plot(kind='bar', stacked=True)\n",
    "plt.title('Traveller Type Preferences by Airline')\n",
    "plt.xlabel('Airline')\n",
    "plt.ylabel('Proportion')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title='Traveller Type')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f10d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a SentimentIntensityAnalyzer object\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Apply sentiment analysis to each review in the full_review column\n",
    "df['sentiment'] = df['full_review'].apply(lambda x: analyzer.polarity_scores(x)['compound'])\n",
    "\n",
    "# Categorize sentiment as positive, negative, or neutral based on compound score\n",
    "df['sentiment_category'] = df['sentiment'].apply(lambda x: 'Positive' if x > 0 else ('Negative' if x < 0 else 'Neutral'))\n",
    "\n",
    "# Normalize the data by calculating the proportion of each sentiment category for each airline\n",
    "normalized_data = df.groupby(['airline', 'sentiment_category']).size() / df.groupby('airline').size()\n",
    "\n",
    "# Reset index to make the DataFrame suitable for plotting\n",
    "normalized_data = normalized_data.reset_index(name='proportion')\n",
    "\n",
    "# Plot the distribution of sentiment categories for each airline\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(data=normalized_data, x='airline', y='proportion', hue='sentiment_category')\n",
    "plt.title('Distribution of Sentiment Categories in Reviews by Airline')\n",
    "plt.xlabel('Airline')\n",
    "plt.ylabel('Proportion')\n",
    "plt.legend(title='Sentiment Category')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b094a8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMN_NAMES=['Review','Sentiment']\n",
    "reviews=pd.read_excel('sentiment.xlsx', names=COLUMN_NAMES)\n",
    "reviews.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5d61f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(reviews)\n",
    "\n",
    "#replace all recommended review with 1\n",
    "df['Sentiment'] = df['Sentiment'].replace('Recommended', 1)\n",
    "\n",
    "#replace all not recommended review with 0\n",
    "df['Sentiment'] = df['Sentiment'].fillna(0)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af1ba30",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.Sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904c82e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_counts = df.Sentiment.value_counts().to_frame()\n",
    "review_counts.index = pd.Series(['Negative','Positive'])\n",
    "sentiment_counts_sorted = review_counts.sort_values(by='Sentiment', ascending=True)\n",
    "sentiment_counts_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20f65f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    text = re.sub(r'[\\W]+', ' ', text.lower())\n",
    "    text = text.replace(\"hadn't\", \"had not\")\\\n",
    "                .replace(\"wasn't\", \"was not\")\\\n",
    "                .replace(\"didn't\", \"did not\")\\\n",
    "                .replace(\"didn t\", \"did not\")\\\n",
    "                .replace(\"couldn't\", \"could not\")\\\n",
    "                .replace(\"shouldn't\", \"should not\")\\\n",
    "                .replace(\"wouldn't\", \"would not\")\\\n",
    "                .replace(\"doesn't\", \"does not\")\\\n",
    "                .replace(\"aren't\", \"are not\")\\\n",
    "                .replace(\"weren't\", \"were not\")\\\n",
    "                .replace(\"hasn't\", \"has not\")\\\n",
    "                .replace(\"haven't\", \"have not\")\\\n",
    "                .replace(\"won't\", \"will not\")\\\n",
    "                .replace(\"isn't\", \"is not\")\\\n",
    "                .replace(\"aren't\", \"are not\")\\\n",
    "                .replace(\"doesn't\", \"does not\")\\\n",
    "                .replace(\"haven't\", \"have not\")\\\n",
    "                .replace(\"mustn't\", \"must not\")\\\n",
    "                .replace(\"shan't\", \"shall not\")\\\n",
    "                .replace(\"mightn't\", \"might not\")\\\n",
    "                .replace(\"needn't\", \"need not\")\\\n",
    "                .replace(\"oughtn't\", \"ought not\")\\\n",
    "                .replace(\"ain't\", \"am not / is not / are not\")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478bf02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Review=df.Review.apply(clean)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3c55fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.Review\n",
    "Y=df.Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2dd6676",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = set()\n",
    "for data_point in X:\n",
    "    for word in data_point.split(' '):\n",
    "        vocabulary.add(word)\n",
    "vocabulary = list(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22b191c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f42591",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d33e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_encoded = []\n",
    "\n",
    "def encode_sentence(sentence):\n",
    "    sentence_encoded = [0] * len(vocabulary)\n",
    "    for i in range(len(vocabulary)):\n",
    "        if vocabulary[i] in sentence.split(' '):\n",
    "            sentence_encoded[i] = 1\n",
    "    return sentence_encoded\n",
    "\n",
    "X_encoded = [encode_sentence(sentence) for sentence in X]\n",
    "\n",
    "len(X_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035dd444",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = list(set(Y))\n",
    "\n",
    "Y_encoded = []\n",
    "for data_point in Y:\n",
    "    data_point_encoded = [0] * len(classes)\n",
    "    for i in range(len(classes)):\n",
    "        if classes[i] == data_point:\n",
    "            data_point_encoded[i] = 1\n",
    "    Y_encoded.append(data_point_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67dad42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X_encoded, Y_encoded, test_size=0.3,\n",
    "                                                   random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668c4c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs=40\n",
    "model = Sequential()\n",
    "model.add(Dense(units=64, activation='sigmoid',\n",
    "               input_dim=len(X_train[0])))\n",
    "model.add(Dense(units=len(Y_train[0]), activation='softmax'))\n",
    "model.compile(loss=categorical_crossentropy, metrics=['acc'],\n",
    "             optimizer=SGD(learning_rate=0.05,\n",
    "                          momentum=0.9, nesterov=True))\n",
    "history=model.fit(np.array(X_train), np.array(Y_train),\n",
    "                 epochs=num_epochs,\n",
    "                 batch_size=16,\n",
    "                 validation_data=(X_test,Y_test),\n",
    "                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec817cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graphs(H, metric):\n",
    "    plt.style.use(\"ggplot\")\n",
    "    plt.figure()\n",
    "    plt.plot(np.arange(0, num_epochs), H.history[\"loss\"], label=\"train_loss\")\n",
    "    plt.plot(np.arange(0, num_epochs), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "    plt.plot(np.arange(0, num_epochs), H.history[\"acc\"], label=\"train_acc\")\n",
    "    plt.plot(np.arange(0, num_epochs), H.history[\"val_acc\"], label=\"val_acc\")\n",
    "    plt.title(\"Training Loss and Accuracy\")\n",
    "    plt.xlabel(\"Epoch #\")\n",
    "    plt.ylabel(\"Loss/Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.savefig(\"model history\")\n",
    "    plt.show()\n",
    "plot_graphs(history, 'acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75a1b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016555f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds=[argmax(each) for each in preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88af3753",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_cm= [argmax(each) for each in Y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06100dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(Y_test_cm, preds)\n",
    "df_cm = pd.DataFrame(cm, index=['Negative','Positive'], columns=['Negative','Positive'])\n",
    "df_cm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68370b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(Y_test_cm, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e899c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_new_sentence(sentence):\n",
    "    sentence=clean(sentence)\n",
    "    #sentence = preprocess_data([sentence])[0]\n",
    "    sentence_encoded = [0] * len(vocabulary)\n",
    "    for i in range(len(vocabulary)):\n",
    "        if vocabulary[i] in sentence.split(' '):\n",
    "            sentence_encoded[i] = 1\n",
    "    return sentence_encoded\n",
    "\n",
    "#X_encoded = [encode_sentence(sentence) for sentence in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc4074a",
   "metadata": {},
   "outputs": [],
   "source": [
    "newPositiveText='The staff were most helpful'\n",
    "newNegativeText='I hate this airline food.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17ea8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(encode_new_sentence(newPositiveText))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47c9c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_results(text):\n",
    "    pred=model.predict(np.array([encode_new_sentence(text)]))\n",
    "    if argmax(pred) ==1:\n",
    "        #print(argmax(pred), *pred[:,argmax(pred)])\n",
    "        print(\"'{}'\".format(text))\n",
    "        print('Prediction: Positive {:.2%}'.format(*pred[:,argmax(pred)]))\n",
    "    else:\n",
    "        print(\"'{}'\".format(text))\n",
    "        print('Prediction: Negative {:.2%}'.format(*pred[:,argmax(pred)]))\n",
    "predict_results(newPositiveText)\n",
    "predict_results(newNegativeText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d330d14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_count = 97  \n",
    "negative_count = 101 \n",
    "\n",
    "# Labels for the sentiments\n",
    "sentiments = ['Positive', 'Negative']\n",
    "\n",
    "# Counts of each sentiment\n",
    "counts = [positive_count, negative_count]\n",
    "\n",
    "# Plotting a bar plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(sentiments, counts, color=['green', 'red'])\n",
    "plt.xlabel('Sentiment')\n",
    "plt.ylabel('No. of reviews')\n",
    "plt.title('Distribution of Sentiments in Reviews')\n",
    "plt.show()\n",
    "\n",
    "# Plotting a pie chart\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.pie(counts, labels=sentiments, autopct='%1.1f%%', colors=['green', 'red'])\n",
    "plt.title('Distribution of Sentiments in Reviews')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
